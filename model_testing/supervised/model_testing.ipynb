{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup: train_test split, undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pullback today</td>\n",
       "      <td>1639642896</td>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look! The teddy bear picnic is starting! Lol</td>\n",
       "      <td>1639642665</td>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>1639642565</td>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classic inflation of calls in order to load u...</td>\n",
       "      <td>1639641515</td>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guys, AAPL consolidating well and ready to go...</td>\n",
       "      <td>1639641435</td>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36276</th>\n",
       "      <td>great day üëçüëç</td>\n",
       "      <td>1640153385</td>\n",
       "      <td>$V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36277</th>\n",
       "      <td>inverse head n shoulders.... 222 possible tom...</td>\n",
       "      <td>1640149580</td>\n",
       "      <td>$V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36278</th>\n",
       "      <td>[15s. delayed]: Issued Press Release on Decem...</td>\n",
       "      <td>1640148346</td>\n",
       "      <td>$V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36279</th>\n",
       "      <td>damn putting in some work last couple of weeks..</td>\n",
       "      <td>1640139998</td>\n",
       "      <td>$V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36280</th>\n",
       "      <td>[Dec-23 212.50 Puts] Option volume Up +400.00...</td>\n",
       "      <td>1640136301</td>\n",
       "      <td>$V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36281 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text        time symbols\n",
       "0                                         pullback today  1639642896   $AAPL\n",
       "1           look! The teddy bear picnic is starting! Lol  1639642665   $AAPL\n",
       "2                                                         1639642565   $AAPL\n",
       "3       classic inflation of calls in order to load u...  1639641515   $AAPL\n",
       "4       Guys, AAPL consolidating well and ready to go...  1639641435   $AAPL\n",
       "...                                                  ...         ...     ...\n",
       "36276                                       great day üëçüëç  1640153385      $V\n",
       "36277   inverse head n shoulders.... 222 possible tom...  1640149580      $V\n",
       "36278   [15s. delayed]: Issued Press Release on Decem...  1640148346      $V\n",
       "36279   damn putting in some work last couple of weeks..  1640139998      $V\n",
       "36280   [Dec-23 212.50 Puts] Option volume Up +400.00...  1640136301      $V\n",
       "\n",
       "[36281 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path(os.getcwd())   # 'c:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\JPM Fintech\\\\HKUST-x-J.P.-Morgan-Fintech-Mentorship-Program\\\\model_testing\\\\supervised'\n",
    "directory = directory.parent.parent.parent.joinpath(\"data\")  # 'c:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\JPM Fintech\\\\data'\n",
    "df = pd.read_pickle(directory.joinpath(\"stocktwits_processed_without_multiple_sample.pkl\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(sample=1000, ratio=0.8, is_token=True, sample_method=0):\n",
    "    # set directory\n",
    "    directory = Path(os.getcwd())   # 'c:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\JPM Fintech\\\\HKUST-x-J.P.-Morgan-Fintech-Mentorship-Program\\\\model_testing\\\\supervised'\n",
    "    directory = directory.parent.parent.parent.joinpath(\"data\")  # 'c:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\JPM Fintech\\\\data'\n",
    "    df = pd.read_pickle(directory.joinpath(\"stocktwits_processed_without_multiple_sample.pkl\"))\n",
    "    \n",
    "    # remove symbols with too little sample size\n",
    "    df = df.groupby('symbols').filter(lambda x : len(x)>sample)\n",
    "\n",
    "    if sample_method == 0:\n",
    "        # turn all symbols into the same sample size\n",
    "        i = sample\n",
    "        for j in set(df['symbols']):\n",
    "            df = df[df['symbols'] != j].append(df[df['symbols'] == j].sample(i), ignore_index=True)\n",
    "        #print(df['symbols'].value_counts())\n",
    "    \n",
    "    # train_test split\n",
    "    df_train = df.sample(frac=ratio,random_state=200)\n",
    "    df_test = df.drop(df_train.index)\n",
    "\n",
    "    if is_token:\n",
    "        X_train = df_train.tokens\n",
    "        X_test = df_test.tokens\n",
    "    else:\n",
    "        X_train = df_train.text\n",
    "        X_test = df_test.text\n",
    "        \n",
    "    y_train = df_train.symbols\n",
    "    y_test = df_test.symbols\n",
    "\n",
    "    print_str = \"{} unique classes\\t{} training samples\\t{} test samples\".format(len(set(y_train)), len(X_train), len(X_test))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, print_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def model(X_train, X_test, y_train, y_test, model_method, sample_method):\n",
    "    # Build the model\n",
    "    model = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer())])\n",
    "\n",
    "    if sample_method == 1:\n",
    "        model.steps.append(['smote', SMOTE(random_state=12)])\n",
    "    elif sample_method == 2:\n",
    "        model.steps.append(['nm', NearMiss()])\n",
    "\n",
    "    if model_method == 0:\n",
    "        model.steps.append(['clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)])\n",
    "        #model.steps.append(['clf', SVC()])\n",
    "        #param_grid = {'clf__C': [0.1, 1, 10, 100, 1000],\n",
    "              #'clf__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              #'clf__kernel': ['rbf', 'linear','polynomial']}\n",
    "\n",
    "    elif model_method == 1:\n",
    "        model.steps.append(['clf', MultinomialNB()])\n",
    "        #param_grid = {\n",
    "  #'clf__alpha': np.linspace(0.5, 1.5, 6),\n",
    "  #'clf__fit_prior': [True, False], }\n",
    "  \n",
    "    elif model_method == 2:\n",
    "        model.steps.append(['clf', LogisticRegression(n_jobs=1, C=1e5)])\n",
    "\n",
    "    #model = GridSearchCV(model, param_grid, n_jobs=2)\n",
    "    #print(model)\n",
    "    # Train the model using the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict the symbols of the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # accuracy\n",
    "    #print(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "    # plot the confusion matrix\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    #sns.heatmap(mat.T, square = True, annot=True, fmt = \"d\", xticklabels=set(y_train),yticklabels=set(y_train))\n",
    "    #plt.xlabel(\"true labels\")\n",
    "    #plt.ylabel(\"predicted label\")\n",
    "    #plt.show()\n",
    "\n",
    "    return accuracy_score(y_test, y_pred), classification_report(y_test, y_pred,target_names=set(y_train)), mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:290\tratio:0.7\ttoken:False\n",
      "12 unique classes\t2436 training samples\t1044 test samples\n",
      "0: 0.471455938697318\n",
      "\n",
      "sample:290\tratio:0.7\ttoken:False\n",
      "12 unique classes\t2436 training samples\t1044 test samples\n",
      "1: 0.3977011494252874\n",
      "\n",
      "sample:290\tratio:0.7\ttoken:False\n",
      "12 unique classes\t2436 training samples\t1044 test samples\n",
      "2: 0.4523946360153256\n",
      "\n",
      "sample:500\tratio:0.7\ttoken:False\n",
      "10 unique classes\t3500 training samples\t1500 test samples\n",
      "0: 0.4945333333333333\n",
      "\n",
      "sample:500\tratio:0.7\ttoken:False\n",
      "10 unique classes\t3500 training samples\t1500 test samples\n",
      "1: 0.43273333333333336\n",
      "\n",
      "sample:500\tratio:0.7\ttoken:False\n",
      "10 unique classes\t3500 training samples\t1500 test samples\n",
      "2: 0.47859999999999997\n",
      "\n",
      "sample:1000\tratio:0.7\ttoken:False\n",
      "5 unique classes\t3500 training samples\t1500 test samples\n",
      "0: 0.4905333333333332\n",
      "\n",
      "sample:1000\tratio:0.7\ttoken:False\n",
      "5 unique classes\t3500 training samples\t1500 test samples\n",
      "1: 0.46419999999999995\n",
      "\n",
      "sample:1000\tratio:0.7\ttoken:False\n",
      "5 unique classes\t3500 training samples\t1500 test samples\n",
      "2: 0.48053333333333326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "\n",
    "model_no = 0\n",
    "\n",
    "for s in [290,500,1000]:\n",
    "    for r in [0.7]:\n",
    "        for t in [False]:\n",
    "            for i in range(0, 3):\n",
    "                print('sample:{}\\tratio:{}\\ttoken:{}'.format(s,r,t))\n",
    "        \n",
    "                scores = []\n",
    "                for j in range(iteration):\n",
    "                    X_train, X_test, y_train, y_test, print_str = setup(s, r, t, model_no)\n",
    "                    if j == 0:\n",
    "                        print(print_str)\n",
    "                    score,a,b = model(X_train, X_test, y_train, y_test, i, model_no)\n",
    "                    scores.append(score)\n",
    "                print('{}: {}'.format(i, sum(scores)/len(scores)))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(b.T, square = True, annot=True, fmt = \"d\", xticklabels=set(y_train),yticklabels=set(y_train))\n",
    "plt.xlabel(\"true labels\")\n",
    "plt.ylabel(\"predicted label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:500\tratio:0.7\ttoken:True\n",
      "18 unique classes\t42809 training samples\t18347 test samples\n",
      "SVM: 0.3265383986482804\n",
      "\n",
      "18 unique classes\t42809 training samples\t18347 test samples\n",
      "NB: 0.3506295307134682\n",
      "\n",
      "18 unique classes\t42809 training samples\t18347 test samples\n",
      "logreg: 0.34561508693519377\n",
      "\n",
      "sample:1000\tratio:0.7\ttoken:True\n",
      "12 unique classes\t39831 training samples\t17071 test samples\n",
      "SVM: 0.38656200574072985\n",
      "\n",
      "12 unique classes\t39831 training samples\t17071 test samples\n",
      "NB: 0.39470446956827365\n",
      "\n",
      "12 unique classes\t39831 training samples\t17071 test samples\n",
      "logreg: 0.38257864214164367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "\n",
    "for s in [500,1000]:\n",
    "    for r in [0.7]:\n",
    "        for t in [True]:\n",
    "            print('sample:{}\\tratio:{}\\ttoken:{}'.format(s,r,t))\n",
    "    \n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 1)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 0, 1)[0]\n",
    "                scores.append(score)\n",
    "            print('SVM: {}'.format(sum(scores)/len(scores)))\n",
    "            print()\n",
    "        \n",
    "\n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 1)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 1, 1)[0]\n",
    "                scores.append(score)\n",
    "            print('NB: {}'.format(sum(scores)/len(scores)))\n",
    "            print()\n",
    "\n",
    "        \n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 1)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 2, 1)[0]\n",
    "                scores.append(score)\n",
    "            print('logreg: {}'.format(sum(scores)/len(scores)))\n",
    "        \n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:500\tratio:0.7\ttoken:True\n",
      "18 unique classes\t42809 training samples\t18347 test samples\n",
      "SVM: 0.08758925164877093\n",
      "\n",
      "18 unique classes\t42809 training samples\t18347 test samples\n",
      "NB: 0.08682618411729438\n",
      "\n",
      "18 unique classes\t42809 training samples\t18347 test samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16856/2834778151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logreg: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\sklearn\\utils\\_testing.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16856/3711944309.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, X_test, y_train, y_test, model_method, sample_method)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Train the model using the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Predict the symbols of the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[0;32m   1590\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             ]\n\u001b[1;32m--> 806\u001b[1;33m             opt_res = optimize.minimize(\n\u001b[0m\u001b[0;32m    807\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    621\u001b[0m                                   **options)\n\u001b[0;32m    622\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    625\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jpm\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    352\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                        isave, dsave, maxls)\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0mtask_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'FG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;31m# The minimization routine wants f and g at the current x.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "\n",
    "for s in [500,1000]:\n",
    "    for r in [0.7]:\n",
    "        for t in [True]:\n",
    "            print('sample:{}\\tratio:{}\\ttoken:{}'.format(s,r,t))\n",
    "    \n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 2)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 0, 2)[0]\n",
    "                scores.append(score)\n",
    "            print('SVM: {}'.format(sum(scores)/len(scores)))\n",
    "            print()\n",
    "        \n",
    "\n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 2)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 1, 2)[0]\n",
    "                scores.append(score)\n",
    "            print('NB: {}'.format(sum(scores)/len(scores)))\n",
    "            print()\n",
    "\n",
    "        \n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 2)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 2, 2)[0]\n",
    "                scores.append(score)\n",
    "            print('logreg: {}'.format(sum(scores)/len(scores)))\n",
    "        \n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b81dac28726c83b00d3c6dae9e63a43b8c5453f676fc94493b94bdbc8172050b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('jpm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
