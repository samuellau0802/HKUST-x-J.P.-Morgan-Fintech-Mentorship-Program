{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(sample=1000, ratio=0.8, is_token=True, sample_method=0):\n",
    "    # set directory\n",
    "    directory = Path(os.getcwd())   # 'c:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\JPM Fintech\\\\HKUST-x-J.P.-Morgan-Fintech-Mentorship-Program\\\\model_testing\\\\supervised'\n",
    "    directory = directory.parent.parent.parent.parent.joinpath(\"data\")  # 'c:\\\\Users\\\\samue\\\\OneDrive\\\\Desktop\\\\JPM Fintech\\\\data'\n",
    "    df = pd.read_pickle(directory.joinpath(\"stocktwits_processed_sample.pkl\"))\n",
    "\n",
    "    # remove symbols with too little sample size\n",
    "    df = df.groupby('symbols').filter(lambda x : len(x)>sample)\n",
    "\n",
    "    if sample_method == 0:\n",
    "        # turn all symbols into the same sample size\n",
    "        i = sample\n",
    "        for j in set(df['symbols']):\n",
    "            df = df[df['symbols'] != j].append(df[df['symbols'] == j].sample(i), ignore_index=True)\n",
    "        #print(df['symbols'].value_counts())\n",
    "\n",
    "    df_test = pd.DataFrame(df[['text', 'symbols']])\n",
    "    df['time'] = [datetime.date.fromtimestamp(date) for date in df['time']]\n",
    "    df_test['text'] = [j[0]+j[1] for j in list(zip(list([str(i) for i in df['time']]), list(df['text'])))]\n",
    "\n",
    "    df_train = df_test.sample(frac=0.8,random_state=200)\n",
    "    df_test = df_test.drop(df_train.index)\n",
    "\n",
    "    if is_token:\n",
    "        X_train = df_train.tokens\n",
    "        X_test = df_test.tokens\n",
    "    else:\n",
    "        X_train = df_train.text\n",
    "        X_test = df_test.text\n",
    "        \n",
    "    y_train = df_train.symbols\n",
    "    y_test = df_test.symbols\n",
    "\n",
    "    print_str = \"{} unique classes\\t{} training samples\\t{} test samples\".format(len(set(y_train)), len(X_train), len(X_test))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, print_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def model(X_train, X_test, y_train, y_test, model_method, sample_method):\n",
    "    # Build the model\n",
    "    model = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer())])\n",
    "\n",
    "    if sample_method == 1:\n",
    "        model.steps.append(['smote', SMOTE(random_state=12)])\n",
    "    elif sample_method == 2:\n",
    "        model.steps.append(['nm', NearMiss()])\n",
    "\n",
    "    if model_method == 0:\n",
    "        model.steps.append(['clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)])\n",
    "    elif model_method == 1:\n",
    "        model.steps.append(['clf', MultinomialNB()])\n",
    "    elif model_method == 2:\n",
    "        model.steps.append(['clf', LogisticRegression(n_jobs=1, C=1e5)])\n",
    "\n",
    "    # Train the model using the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict the symbols of the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # accuracy\n",
    "    #print(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "    # plot the confusion matrix\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    #sns.heatmap(mat.T, square = True, annot=True, fmt = \"d\", xticklabels=set(y_train),yticklabels=set(y_train))\n",
    "    #plt.xlabel(\"true labels\")\n",
    "    #plt.ylabel(\"predicted label\")\n",
    "    #plt.show()\n",
    "\n",
    "    return accuracy_score(y_test, y_pred), classification_report(y_test, y_pred,target_names=set(y_train)), mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:500\tratio:0.7\ttoken:False\n",
      "18 unique classes\t7200 training samples\t1800 test samples\n",
      "SVM: 0.33061111111111113\n",
      "\n",
      "18 unique classes\t7200 training samples\t1800 test samples\n",
      "NB: 0.2940555555555555\n",
      "\n",
      "18 unique classes\t7200 training samples\t1800 test samples\n",
      "logreg: 0.32788888888888895\n",
      "\n",
      "sample:1000\tratio:0.7\ttoken:False\n",
      "12 unique classes\t9600 training samples\t2400 test samples\n",
      "SVM: 0.38575000000000004\n",
      "\n",
      "12 unique classes\t9600 training samples\t2400 test samples\n",
      "NB: 0.36225\n",
      "\n",
      "12 unique classes\t9600 training samples\t2400 test samples\n",
      "logreg: 0.37070833333333336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "\n",
    "for s in [500,1000]:\n",
    "    for r in [0.7]:\n",
    "        for t in [False]:\n",
    "            print('sample:{}\\tratio:{}\\ttoken:{}'.format(s,r,t))\n",
    "    \n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 0)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 0, 0)[0]\n",
    "                scores.append(score)\n",
    "            print('SVM: {}'.format(sum(scores)/len(scores)))\n",
    "            print()\n",
    "        \n",
    "\n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 0)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 1, 0)[0]\n",
    "                scores.append(score)\n",
    "            print('NB: {}'.format(sum(scores)/len(scores)))\n",
    "            print()\n",
    "\n",
    "        \n",
    "            scores = []\n",
    "            for i in range(iteration):\n",
    "                X_train, X_test, y_train, y_test, print_str = setup(s, r, t, 0)\n",
    "                if i == 0:\n",
    "                    print(print_str)\n",
    "                score = model(X_train, X_test, y_train, y_test, 2, 0)[0]\n",
    "                scores.append(score)\n",
    "            print('logreg: {}'.format(sum(scores)/len(scores)))\n",
    "        \n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b81dac28726c83b00d3c6dae9e63a43b8c5453f676fc94493b94bdbc8172050b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('jpm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
